

# 论文阅读

**A Survey of Machine Learning for Big Code and Naturalness**

- 自然性假设

  软件是人类交流的一种形式，软件语料库具有与自然语言语料库相似的统计特性，可以利用这些特性来构建更好的软件工程工具。

- 代码和文本的区别

  可执行性；形式语言；跨渠道沟通（面向计算机和面向人）

- 概率模型

  - 代码生成
    - Language Models. 
    - Code Transducer Models.
    - Multimodal Models. 多模代码生成模型学习非代码模式m的中间表示，并使用它生成代码。
  - 代码表示
    - 分布式表示 见第二篇论文
  - 模式挖掘

- 应用

  - Recommender Systems 推荐
  - Inferring Coding Conventions 风格约束
  - Code Defects 代码检测
  - Code Translation, Copying, and Clones 翻译和拷贝
  - **Code to Text and Text to Code**
  - **Documentation, Traceability and Information Retrieval 文档、代码搜索**
  - Program Synthesis 程序合成
  - Program Analysis 程序分析



问题：

文章在第9页末和第10页初解释了为什么PCFG在NLP中广泛应用，而不适合作为code的模型，我在去了解了PCFG之后还是不能理解为什么PCFG不能在code领域使用，文章的第三部分介绍了文本和代码影响模型设计的几个差别，是这其中哪一个差别导致了PCFG的不适用？



**code2vec: Learning Distributed Representations of Code**

Distributed Representations：将代码段表示为单个固定长度的代码向量，用于预测代码段的语义属性

文章的主要贡献：

* 基于路径的注意力模型，用于学习任意大小代码片段的向量。该模型允许将一个离散对象的程序嵌入到一个连续的空间中，这样它就可以为各种任务输入一个深度学习管道。
* 对预测跨项目方法名称进行定量评估，对超过1400万种实际数据方法进行培训，并与以前的工作进行比较。
* 定性评估，解释模型在进行预测时学会给予不同路径背景的关注。
* 方法名嵌入的集合，通常将语义相似的名称分配给相似的向量，甚至允许使用简单的向量算法计算类比。
* 我们的模型在泛化能力和空间复杂性方面具有显著优势。

问题：

4.5 Design Decisions中说假定path-context的顺序没有很大影响，从现实中我对代码的理解，代码的顺序影响还是挺大的，不像自然语言那么包容，要表示一段代码的话，为什么会选择忽略顺序呢？后续的学习中使用的这个向量丢失了顺序信息真的没问题吗？



**Maybe Deep Neural Networks are the Best Choice for Modeling Source Code**

开放词汇神经语言模型，该模型不局限于标识符名称的固定词汇表，基于代码标记自动分割成更小的子字单元，学习标识符名称中常见的统计内部模式。

问题：

没理解第五页的算法，“A sufficient number of search iterations have been completed, i.e. iters > 7.”，这里的搜索迭代是指什么？另外，是否存在满足结束要求之后还没有拼凑出一个token的情况？



**Deep API Learning**

基于深度学习的方法Deepapi，用于为给定的自然语言查询生成API使用序列。

将RNN编解码器模型应用于API学习，将用户查询作为源语言，将API序列作为目标语言。

问题：

上上一片论文中忽略了path-context的顺序，在这篇论文的场景里我倒觉得API的顺序真的作用不大。查询的时候只想得到可能会用到哪些API，所以API跟查询的自然语言的对应应该更紧密，而跟前后可能跟着什么API的联系应该削弱？



**Deep Code Search**

编码描述嵌入神经网络（Code-Description Embedding Neural Network）

codenn没有匹配文本相似性，而是将代码片段和自然语言描述共同嵌入到高维向量空间中，从而使代码片段及其对应的描述具有相似的向量。使用统一的向量表示，可以根据向量检索与自然语言查询相关的代码片段。还可以识别语义相关的词，并处理查询中不相关/嘈杂的关键字。

考虑源代码的三个方面：方法名、API调用序列和源代码中包含的令牌，对于每个代码片段（在方法级别），我们提取这三个方面的信息。每一个都单独嵌入，然后组合成一个表示整个代码的向量。

问题：

这篇文章中选择的训练模型的loss是：一个常量-跟正确向量的距离+跟（随机选择的）错误向量的距离，选择这样的loss在其他模型中是常见的做法吗？我怎么觉得不太合适呀？只选择了一个错误向量，万一随机选择到的向量本来就跟正确向量很接近呢？

**Aroma: Code Recommendation via Structural Code Search**

代码推荐工具aroma。

工作原理：首先索引一个大的代码集。解析集合中每个方法的主体，并创建其解析树，从每个解析树中提取一组结构特征。在推荐阶段，给定一个查询代码片段，用轻量级搜索找出一组特征集与所选方法体的特征集重叠最多的方法体，接下来对每个检索到的代码段进行删减，以便得到的代码段与查询代码段最大程度地相似。在最后一个阶段，aroma根据代码片段的相似性对其进行聚类，并将每个集群中的代码片段交叉，以得出推荐的代码片段（最后一步是为了防止多个片段给出相似建议）。

问题：

不理解删减算法，怎样区分代码是与查询代码无关的还是需要添加来达到优化效果的？



**When Deep Learning Met Code Search**

比较神经代码搜索系统，使用相同语料库进行评估

unif：基础NCS技术的监督扩展

unif优于一些更复杂的网络设计（codenn和scs），以及NCS（无监督技术）。

理想化的训练语料库可以使被监督的技术提供非常好的性能，但在用注释和代码的训练语料库时监督作用并不明显。

问题：

对结果感到诧异，更复杂的网络设计的效果甚至不如unif，其中的原因是什么呢？明明看起来CODEnn获取了更全面的信息，是分配的权重不对嘛？还是说是其他因素抑制了他们发挥作用（比如说训练集本身不够好）？

# 写程序的痛点

1. 总是在环境/依赖上出现问题
2. 不愿意写文档
3. 不知道有什么现成的库里已经提供了想写的方法
4. 不能充分利用特定语言提供的方法或语法糖来写出最优雅简洁的代码（像haskell的代码提示就能检测出可以使用“.”或“$”来简化的代码）

# 示例模型

![img](https://cdn-images-1.medium.com/max/1600/1*HxrVL3bDLD8G0elzF5cp4w.png)

1. 安装docker
2. 获取hamelsmu/ml-gpu镜像
3. docker run -it --name ml -p 7777:8888 hamelsmu/ml-gpu
4. jupyter notebook --allow-root --ip=0.0.0.0
5. 在jupyter notebook 中尝试教程提供的notebook

## 遇到的问题

### 1 Preprocess Data 

1. numpy版本问题

   ![image-20190705160521774](/Users/yutao/Library/Application Support/typora-user-images/image-20190705160521774.png)

   解决：pip3 uninstall numpy 

   ​			pip3 install numpy==1.14.3 -U

2. 下载数据失败

   ![image-20190705162425756](/Users/yutao/Library/Application Support/typora-user-images/image-20190705162425756.png)

   网络问题？下的很慢很慢

   解决：减少数据量 10 -> 1

   ​			先下到本地，从本地读取

   (后来发现1个文件里就有12万条数据 减少到1000条加快速度)

3. ![image-20190705174022557](/Users/yutao/Library/Application Support/typora-user-images/image-20190705174022557.png)

   这里的cpu_core记得修改一下

结果：得到处理好的data

###2 Train Function Summarizer With Keras + TF.ipynb

1. ![image-20190705190054741](/Users/yutao/Library/Application Support/typora-user-images/image-20190705190054741.png)

   无法导入Tensorflow   环境有问题？？？？

   解决：使用cpu版本

2. 训练的时候总是会 KernelRestarter: restarting kernel

   原因：发现原来的batch_size为1100，总共的训练样本才1041个。。。

   解决：调小了batch_size

结果：由于训练样本太少了，结果很不理想

![image-20190705195425560](/Users/yutao/Library/Application Support/typora-user-images/image-20190705195425560.png)

基本上都是the of the of

bleu score为0.040492225300332904

### 3 Train Language Model Using FastAI

1. 这里的文件从哪来的呢？

   ![image-20190705201510058](/Users/yutao/Library/Application Support/typora-user-images/image-20190705201510058.png)

   看不懂。。先跳过，后面有训练好的模型可以直接用

2. RuntimeError: cuda runtime error (35) : CUDA driver version is insufficient for CUDA runtime version at torch/csrc/cuda/Module.cpp:107

   ![image-20190705203344649](/Users/yutao/Library/Application Support/typora-user-images/image-20190705203344649.png)

   ??

   没关系 这只是评估效果的，不影响第4步

### 4 Train Model To Map Code Embeddings to Language Embeddings

1. 在这里kernel又挂了![image-20190705203530321](/Users/yutao/Library/Application Support/typora-user-images/image-20190705203530321.png)

   ？？

   继续不下去。。。